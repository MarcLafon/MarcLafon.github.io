@article{Vapnik1992,
author = {Vapnik, Vladimir},
isbn = {1-55860-222-4},
journal = {Advances in neural information processing systems},
mendeley-groups = {ML {\&} DL/DAC/M2A - double descent},
pages = {831--838},
title = {Principles of risk minimization for learning theory},
url = {http://papers.nips.cc/paper/506-principles-of-risk-minimization-for-learning-theory},
year = {1992}
}

@article{Canziani2016,
archivePrefix = {arXiv},
arxivId = {1605.07678},
author = {Canziani, Alfredo and Paszke, Adam and Culurciello, Eugenio},
eprint = {1605.07678},
pages = {1--7},
title = {An Analysis of Deep Neural Network Models for Practical Applications},
url = {http://arxiv.org/abs/1605.07678},
year = {2016}
}

@article{Belkin2019,
archivePrefix = {arXiv},
arxivId = {arXiv:1812.11118v2},
author = {Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
doi = {10.1073/pnas.1903070116},
eprint = {arXiv:1812.11118v2},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Bias–variance trade-off,Machine learning,Neural networks},
number = {32},
pages = {15849--15854},
pmid = {31341078},
title = {Reconciling modern machine-learning practice and the classical bias–variance trade-off},
volume = {116},
url = {https://arxiv.org/abs/1812.11118},
year = {2019}
}

@article{Nakkiran2019,
archivePrefix = {arXiv},
arxivId = {1912.02292},
author = {Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya},
eprint = {1912.02292},
pages = {1--24},
title = {Deep Double Descent: Where Bigger Models and More Data Hurt},
url = {http://arxiv.org/abs/1912.02292},
year = {2019}
}

@book{mitchell1980need,
  title={The need for biases in learning generalizations},
  author={Mitchell, Tom M},
  year={1980},
  publisher={Department of Computer Science, Laboratory for Computer Science Research~…}
}

@article{battaglia2018relational,
  title={Relational inductive biases, deep learning, and graph networks},
  author={Battaglia, Peter W and Hamrick, Jessica B and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and others},
  journal={arXiv preprint arXiv:1806.01261},
	url = {http://arxiv.org/abs/1806.01261},
  year={2018}
}

@article{bishop2006pattern,
  title={Pattern recognition},
  author={Bishop, Christopher M},
  journal={Machine learning},
  volume={128},
  number={9},
  year={2006}
}

@article{breiman1983many,
  title={How many variables should be entered in a regression equation?},
  author={Breiman, Leo and Freedman, David},
  journal={Journal of the American Statistical Association},
  volume={78},
  number={381},
  pages={131--136},
  year={1983},
  publisher={Taylor & Francis Group}
}

@article{belkin2020two,
  title={Two models of double descent for weak features},
  author={Belkin, Mikhail and Hsu, Daniel and Xu, Ji},
  journal={SIAM Journal on Mathematics of Data Science},
  volume={2},
  number={4},
  pages={1167--1180},
  year={2020},
  publisher={SIAM}
}

@inproceedings{rahimi2007random,
  title={Random Features for Large-Scale Kernel Machines.},
  author={Rahimi, Ali and Recht, Benjamin and others},
  booktitle={NIPS},
  volume={3},
  number={4},
  pages={5},
  year={2007},
  organization={Citeseer}
}

@article{oymak2020toward,
  title={Toward Moderate Overparameterization: Global Convergence Guarantees for Training Shallow Neural Networks},
  author={Oymak, Samet and Soltanolkotabi, Mahdi},
  journal={IEEE Journal on Selected Areas in Information Theory},
  volume={1},
  number={1},
  pages={84--105},
  year={2020},
  url = {https://arxiv.org/pdf/1902.04674.pdf},
  publisher={IEEE}
}

@article{liu2020toward,
  title={Toward a theory of optimization for over-parameterized systems of non-linear equations: the lessons of deep learning},
  author={Liu, Chaoyue and Zhu, Libin and Belkin, Mikhail},
  journal={arXiv preprint arXiv:2003.00307},
  url = {https://arxiv.org/pdf/2003.00307.pdf},
  year={2020}
}

@article{polyak1963gradient,
  title={Gradient methods for minimizing functionals},
  author={Polyak, Boris Teodorovich},
  journal={Zhurnal Vychislitel'noi Matematiki i Matematicheskoi Fiziki},
  volume={3},
  number={4},
  pages={643--653},
  year={1963},
  publisher={Russian Academy of Sciences, Branch of Mathematical Sciences}
}

@inproceedings{arora2018optimization,
  title={On the optimization of deep networks: Implicit acceleration by overparameterization},
  author={Arora, Sanjeev and Cohen, Nadav and Hazan, Elad},
  booktitle={International Conference on Machine Learning},
  pages={244--253},
  year={2018},
  organization={PMLR}
}

@article{spigler2018jamming,
  title={A jamming transition from under-to over-parametrization affects loss landscape and generalization},
  author={Spigler, Stefano and Geiger, Mario and d'Ascoli, St{\'e}phane and Sagun, Levent and Biroli, Giulio and Wyart, Matthieu},
  journal={arXiv preprint arXiv:1810.09665},
  year={2018}
}

@article{geiger2020scaling,
  title={Scaling description of generalization with number of parameters in deep learning},
  author={Geiger, Mario and Jacot, Arthur and Spigler, Stefano and Gabriel, Franck and Sagun, Levent and d’Ascoli, St{\'e}phane and Biroli, Giulio and Hongler, Cl{\'e}ment and Wyart, Matthieu},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  volume={2020},
  number={2},
  pages={023401},
  year={2020},
  publisher={IOP Publishing}
}

@article{gissin2019implicit,
  title={The implicit bias of depth: How incremental learning drives generalization},
  author={Gissin, Daniel and Shalev-Shwartz, Shai and Daniely, Amit},
  journal={arXiv preprint arXiv:1909.12051},
  url = {https://arxiv.org/pdf/1909.12051.pdf},
  year={2019}
}

@article{neyshabur2015path,
  title={Path-sgd: Path-normalized optimization in deep neural networks},
  author={Neyshabur, Behnam and Salakhutdinov, Ruslan and Srebro, Nathan},
  journal={arXiv preprint arXiv:1506.02617},
  url = {https://arxiv.org/pdf/1506.02617.pdf},
  year={2015}
}

@article{soudry2018implicit,
  title={The implicit bias of gradient descent on separable data},
  author={Soudry, Daniel and Hoffer, Elad and Nacson, Mor Shpigel and Gunasekar, Suriya and Srebro, Nathan},
  journal={The Journal of Machine Learning Research},
  volume={19},
  number={1},
  pages={2822--2878},
  year={2018},
	url = {http://arxiv.org/abs/1710.10345},
  publisher={JMLR. org}
}

@inproceedings{gunasekar2018implicit,
  title={Implicit regularization in matrix factorization},
  author={Gunasekar, Suriya and Woodworth, Blake and Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nathan},
  booktitle={2018 Information Theory and Applications Workshop (ITA)},
  pages={1--10},
  year={2018},
	url = {http://arxiv.org/abs/1705.09280},
  organization={IEEE}
}

@article{chen2020multiple,
  title={Multiple descent: Design your own generalization curve},
  author={Chen, Lin and Min, Yifei and Belkin, Mikhail and Karbasi, Amin},
  journal={arXiv preprint arXiv:2008.01036},
  url = {https://arxiv.org/pdf/2008.01036.pdf},
  year={2020}
}