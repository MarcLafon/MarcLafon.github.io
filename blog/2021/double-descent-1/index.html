<!DOCTYPE html>
<!-- _layouts/distill.html --><html>
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Deep double descent explained (1/4) - Generalization error | Marc  Lafon</title>
    <meta name="author" content="Marc  Lafon">
    <meta name="description" content="A blog post series on the phenomenon of double descent and the role of inductive biases in deep learning.">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%A1&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://marclafon.github.io//blog/2021/double-descent-1/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    


    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Distill js -->
    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    <script src="/assets/js/distillpub/overrides.js"></script>
    
    <!-- Page/Post style -->
    <style type="text/css">
      .definition {
    background: rgba(0, 0, 255, 0.05);  # blue
    color: black;
    border: 2px solid rgba(0, 0, 255, 0.3);
    margin: auto;
    margin-bottom: 15pt;
    padding-top: 10pt;
    padding-right: 10pt;
    padding-left: 10pt;
} .remark {
    background: rgba(255, 165, 0, 0.05);
    color: black;
    border: 2px solid rgba(255, 165, 0, 0.3);
    margin: 15pt auto;
    padding-top: 10pt;
    padding-right: 10pt;
    padding-left: 10pt;
} .theorem {
    background: rgba(255, 0, 0, 0.05);
    color: black;
    border: 2px solid rgba(255, 0, 0, 0.3);
    margin: 15pt auto;
    padding-top: 10pt;
    padding-right: 10pt;
    padding-left: 10pt;
}

    </style>
  </head>

  <body>
<d-front-matter>
    <script async type="text/json">{
      "title": "Deep double descent explained (1/4) - Generalization error",
      "description": "A blog post series on the phenomenon of double descent and the role of inductive biases in deep learning.",
      "published": "May 15, 2021",
      "authors": [
        {
          "author": "Marc Lafon",
          "authorURL": "",
          "affiliations": [
            {
              "name": "Sorbonne University",
              "url": ""
            }
          ]
        },
        {
          "author": "Alexandre Thomas",
          "authorURL": "https://alexandrethm.github.io/",
          "affiliations": [
            {
              "name": "Mines ParisTech & Sorbonne University",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Marc </span>Lafon</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item dropdown ">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">menu</a>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="/">about</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="/blog/">blog</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="/publications/">publications</a>
                </div>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1>Deep double descent explained (1/4) - Generalization error</h1>
        <p>A blog post series on the phenomenon of double descent and the role of inductive biases in deep learning.</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        

        \[\newcommand{\R}{\mathbb{R}}
    \newcommand{\EMC}{\text{EMC}_{P, \epsilon}(\mathcal{T})}
    \DeclareMathOperator*{\argmin}{argmin}\]

<blockquote>
  <p>This post sets the classical statistical learning framework (following <a href="https://m2a.lip6.fr/premier-semestre/" target="\_blank" rel="external nofollow noopener">Statistical Learning course</a> by <a href="https://www.lpsm.paris/pageperso/biau/" target="\_blank" rel="external nofollow noopener">Prof. Gérard Biau</a>) and introduces the double descent phenomenon.</p>

  <p>Cross-posted <a href="https://alexandrethm.github.io/blog/2021/double-descent-1/" target="\_blank" rel="external nofollow noopener">here</a> as well.</p>
</blockquote>

<p><strong>Double descent: going beyond overfitting with bigger models.</strong>
In order to avoid overfitting, <em>conventional wisdom from statistical learning suggests using models that are not too large</em>, or using regularization techniques to control capacity. Yet, in modern deep learning practice, very large over-parameterized models (typically neural networks) are optimized to fit perfectly the training data and still obtain great generalization performance: <em>bigger models are better</em>.</p>

<p>A <a href="https://arxiv.org/abs/1812.11118" target="\_blank" rel="external nofollow noopener">number</a> of <a href="https://arxiv.org/abs/1912.02292" target="\_blank" rel="external nofollow noopener">recent</a> <a href="https://arxiv.org/abs/1809.09349" target="\_blank" rel="external nofollow noopener">articles</a> have observed that, as the model capacity increases, the performance first improves then gets worse (overfitting) until a certain point where it can fit the training data perfectly (interpolation threshold). At this point, increasing model’s capacity actually seems to improve its performance again.
This phenomenon, called <em>double descent</em> by <a href="https://arxiv.org/pdf/1812.11118.pdf" target="\_blank" rel="external nofollow noopener">Belkin et al., 2019</a> <d-cite key="Belkin2019"></d-cite>, is illustrated in the figure below.</p>

<div class="l-body">
    <div class="col-auto">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/posts/double-descent/modeldd.svg">
    </div>
</div>
<div class="caption">
  <p><a name="fig:double_descent_schema"></a>
Model-wise double descent: performance after training models without early-stopping. Taken from <a href="https://openai.com/blog/deep-double-descent/" target="\_blank" rel="external nofollow noopener">this blog post</a>.</p>
</div>

<h2 id="generalization-error--classical-view-and-modern-practice">Generalization error : classical view and modern practice</h2>

<h3 id="definitions-and-results-from-statistical-learning">Definitions and results from statistical learning</h3>

<p>In statistical learning theory, the supervised learning problem consists of finding a good predictor \(h_n: \mathbb{R}^d \rightarrow \{0, 1\}\), based on some training data \(D_n\). The data is typically assumed to come from a certain distribution, i.e. \(D_n = \{(X_1, Y_1), \dots, (X_n, Y_n)\}\) is a collection of \(n\) i.i.d. copies of the random variables \((X, Y)\), taking values in \(\mathbb{R}^d \times \{0, 1\}\) and following a data distribution \(P(X, Y)\). We also restrict ourselves to a given class of predictors by
choosing \(h_n \in \mathcal{H}\).</p>

<div class="definition l-body-outset">
  <p><strong>Definition 1</strong> (True risk).
With \(\ell(h(X), Y) = 𝟙_{(h(X) \neq Y)}\) the 0-1 loss, the
<em>true risk</em> (or <em>true error</em>) of a predictor
\(h: \mathbb{R}^d \rightarrow \{0, 1\}\) is defined as</p>

\[L(h) = \mathbb{E}[\ell(h(X), Y)] = \mathbb{P}(h(X) \neq Y)\]

  <p>The true risk is also called the <em>expected risk</em> or the <em>generalization error</em>.</p>
</div>

<blockquote>
  <p><strong>Remark 1.</strong>
<em>We choose in this section a classification setting, but a regression
setting can be adopted as well, for instance with \(Y\) and \(h_n\) taking
values in \(\mathbb{R}\) (which we will sometimes do in the subsequent
sections). In this case, the 0-1 loss is replaced by other loss
functions, such as the squared error loss</em>
\(\ell(\hat{y}, y) = (\hat{y} - y)^2\).</p>
</blockquote>

<p>In practice, the true distribution of \((X, Y)\) is unknown, so we have to
resort to a proxy measure based on the available data.</p>

<div class="definition l-body-outset">
  <p><strong>Definition 2</strong> (Empirical risk).
The <em>empirical risk</em> of a predictor
\(h: \mathbb{R}^d \rightarrow \mathbb{R}\) on a training set \(D_n\) is
defined as:</p>

\[L_n(h) = \frac{1}{n} \sum_{i=1}^{n} \ell(h(X_i), Y_i)\]

</div>

<div class="definition l-body-outset">
  <p><strong>Definition 3</strong> (Bayes risk).
A predictor \(h^*: \mathbb{R}^d \rightarrow \{0, 1\}\) minimizing the true
risk, i.e. verifying</p>

\[L(h^*) = \inf_{h: \mathbb{R}^d \rightarrow \{0, 1\}} L(h)\]

  <p>is called a <em>Bayes estimator</em>. Its risk \(L^* = L(h^*)\) is called the <em>Bayes risk</em>.</p>
</div>

<p>Using \(D_n\), our objective is to find a predictor \(h_n\) as close as
possible to \(h^*\).</p>

<div class="definition l-body-outset">
  <p><strong>Definition 4</strong> (Consistency).
A predictor \(h_n\) is <em>consistent</em> if</p>

\[\mathbb{E} L(h_n) \underset{n \rightarrow \infty}{\rightarrow} L^*\]

</div>

<p>The <em>empirical risk minimization (ERM)</em> approach <d-cite key="Vapnik1992"></d-cite>
consists in choosing a predictor that minimizes the empirical risk on \(D_n\) :
\(h_n^*\in \text{argmin}_{h \in \mathcal{H}} L_n(h)\). This is something
that can be done or approximated in practice, thanks to a wide range of
algorithms and optimization procedures, but it is also necessary to
ensure that our predictor \(h_n^*\) performs well in general and not only
on training data. Depending on the chosen class of predictors
\(\mathcal{H}\), statistical learning theory can give us guarantees or
insights to make sure \(h_n^*\) generalizes well to unseen data.</p>

<h3 id="classical-view">Classical view</h3>

<p>The gap between any predictor \(h_n \in \mathcal{H}\) and an optimal predictor \(h^*\) can be
decomposed as follows.
\(L(h_n) - L^*= \underbrace{L(h_n) - \inf_{h \in \mathcal{H}} L(h)}_{\text{estimation error}} +
    \underbrace{\inf_{h \in \mathcal{H}} L(h) - L^*}_{\text{approximation error}}\)</p>

<blockquote>
  <p><strong>Remark 2.</strong>
<em>In addition to the approximation error (approximating reality with a
model) and estimation error (learning a model with finite data) which
fits in the statistical learning framework and are the focus of this
post, there is actually another source of error, the <strong>optimization
error</strong>. This is the gap between the risk of the predictor returned by
the optimization procedure (e.g. SGD) and an empirical risk minimizer \(h_n^*\).</em></p>
</blockquote>

<div class="theorem l-body-outset">
  <p><strong>Proposition 5.</strong> <a name="prop:classical-bound"></a>
For any empirical risk minimizer
\(h_n^* \in \text{argmin}_{h \in \mathcal{H}} L_n(h)\), the estimation
error verifies</p>

\[L(h_n^*) - \inf_{h \in \mathcal{H}} L(h) \leq 2 \sup_{h \in \mathcal{H}} |L_n(h) - L(h)|\]

  <p>The term \(|L_n(h) - L(h)|\) is the <em>generalization gap</em>. It is the gap between the empirical risk and the true risk, in other words the difference between a model’s performance on training data and its performance on unseen data drawn from the same distribution.</p>
</div>

<blockquote>
  <p><em>Proof.</em> We have</p>

\[L(h_n^*) - \inf_{h \in \mathcal{H}} L(h)
\leq |L(h_n^*) - L_n(h_n^*)| + |L_n(h_n^*) - \inf_{h \in \mathcal{H}} L(h)|\]

  <p>With</p>

\[|L(h_n^*) - L_n(h_n^*)|
\leq \sup_{h \in \mathcal{H}} |L_n(h) - L(h)|\]

  <p>since \(h_n^*\in \mathcal{H}\), and :</p>

\[|L_n(h_n^*) - \inf_{h \in \mathcal{H}} L(h)|
= |\inf_{h \in \mathcal{H}}L_n(h) - \inf_{h \in \mathcal{H}} L(h)|
\leq \sup_{h \in \mathcal{H}} |L_n(h) - L(h)|\]

  <p>after separating the cases where
\(|\inf_{h \in \mathcal{H}}L_n(h) - \inf_{h \in \mathcal{H}} L(h)| &gt; 0\)
and
\(|\inf_{h \in \mathcal{H}}L_n(h) - \inf_{h \in \mathcal{H}} L(h)| &lt; 0\). ◻</p>
</blockquote>

<p>The classical machine learning strategy is to find the right
\(\mathcal{H}\) to keep both the approximation error and the estimation
error low.</p>

<ol>
  <li>
    <p>When \(\mathcal{H}\) is too small, no predictor \(h \in \mathcal{H}\) is
 able to model the complexity of the data and to approach the Bayes
 risk. This is called <em>underfitting</em>.</p>
  </li>
  <li>
    <p>When \(\mathcal{H}\) is too large, the bound from <a href="#prop:classical-bound">proposition 5</a>
 (maximal generalization gap over \(\mathcal{H}\)) will increase, and the chosen empirical risk
 minimizer \(h_n^*\) may generalize poorly despite having a low
 training error. This is called <em>overfitting</em>.</p>
  </li>
</ol>

<blockquote>
  <p><strong>Remark 3.</strong>
<em>Similarly, the expected error can also be decomposed into a bias term
due to model mis-specification and a variance term due to random noise
being modeled by \(h_n^*\). This is the <strong>bias-variance trade-off</strong>, and is
also highly dependent on the capacity of \(\mathcal{H}\), the chosen class
of predictors.</em></p>
</blockquote>

<blockquote>
  <p><strong>Exercise 1</strong> (Bias-Variance decomposition).
Assume that \(Y = h(X) + \epsilon\), with
\(\mathbb{E}[\epsilon] = 0, Var(\epsilon) = \sigma^2\). Show that, for any
\(x \in \mathbb{R}^d\), the expected error of a predictor \(h_n\) obtained
with the random dataset \(D_n\) is :</p>

\[\mathbb{E}[(Y - h_n(X))^2 | X=x] = (h(x) - \mathbb{E}h_n(x))^2 + \mathbb{E}[(\mathbb{E}h_n(x) - h_n(x))^2] + \sigma^2\]
</blockquote>

<p>In order to ensure a consistent estimator \(h_n\), we can control
\(\mathcal{H}\) explicitly e.g. by choosing the number of features used in
a linear classifier, or the number of layers of a neural network.</p>

<div class="theorem l-body-outset">
  <p><strong>Theorem 6</strong> (Vapnik-Chervonenkis inequality).
For any data distribution \(P(X,Y)\), by using \(V_{\mathcal{H}}\) the
VC-dimension of the class \(\mathcal{H}\) as a measure of the class
complexity, one has</p>

\[\mathbb{E} \sup_{h\in\mathcal{H}} |L_n(h) - L(h)|
    \leq 4 \sqrt{\frac{V_{\mathcal{H}} \log(n+1)}{n}}\]

</div>

<p>A complete introduction to Vapnik-Chervonenkis theory is outside the
scope of this post, but <a href="https://datascience.stackexchange.com/questions/32557/what-is-the-exact-definition-of-vc-dimension" rel="external nofollow noopener" target="_blank">VC-dimension</a> \(V_{\mathcal{H}}\) can be defined as the
cardinality of the largest set of points that can be shattered, i.e.
there is at least one \(h \in \mathcal{H}\) that can assign all possible
labels to the set. Combining this result with <a href="#prop:classical-bound">proposition 5</a>
gives a useful bound on the generalization error for a number of model classes. For instance, if
\(\mathcal{H}\) is a class of linear classifiers using \(d\) features
(potentially non-linear transformations of input \(x\)), then we have :</p>

\[V_{\mathcal{H}} \leq d+1\]

<p>Other measures of the richness of the model class \(\mathcal{H}\) also
exist, such as the <a href="https://en.wikipedia.org/wiki/Rademacher_complexity" rel="external nofollow noopener" target="_blank">Rademacher complexity</a>, and can be useful in
situations where \(V_{\mathcal{H}} = +\infty\), or in regression settings.</p>

<h3 id="modern-practice">Modern practice</h3>

<p>Following results from the <a href="#definitions-and-results-from-statistical-learning">first section</a>,
a widely adopted view is that, after a
certain threshold, “larger models are worse” as they will overfit and
generalize poorly. Yet, in modern machine learning practice, very large
models with enough parameters to reach almost zero training error are
frequently used. Such models are able to fit almost perfectly (i.e.
<em>interpolate</em>) the training data and still generalize well, actually
performing better than smaller models (e.g. to classify 1.2M examples,
AlexNet had 60M parameters and VGG-16 and VGG-19 both exceeded 100M
parameters <d-cite key="Canziani2016"></d-cite>). Understanding generalization of
overparameterized models in modern deep learning is an active field of
research, and we focus on the <em>double descent</em> phenomenon, first
demonstrated by <a href="https://arxiv.org/pdf/1812.11118.pdf" target="\_blank" rel="external nofollow noopener">Belkin et al., 2019</a> <d-cite key="Belkin2019"></d-cite> and illustrated below.</p>

<div class="l-page">
    <div class="col-auto">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/posts/double-descent/double_descent_schema.png">
    </div>
</div>
<div class="caption">
  <p><a name="fig:double_descent_schema"></a>
<strong>Figure 1.</strong> The <em>classical risk curve</em> arising from the bias-variance trade-off
and the <em>double descent risk curve</em> with the observed modern
interpolation regime. Taken from <a href="https://arxiv.org/pdf/1812.11118.pdf" target="\_blank" rel="external nofollow noopener">Belkin et al., 2019</a> <d-cite key="Belkin2019"></d-cite>.</p>
</div>

<p>For simpler class of models, classical statistical learning guarantee
that the test risk decreases when the class of models gets more complex,
until a point where the bounds do not control the risk anymore. However
it seems that, beyond a certain threshold, increasing the capacity of
the models actually decreases the test risk again. This is the “modern”
interpolating regime, with overparameterized models. As this phenomenon
depends not only on the class of predictors \(\mathcal{H}\), but also on
the training algorithm and regularization techniques, we define a
<em>training procedure</em> \(\mathcal{T}\) to be any procedure that takes as
input a dataset \(D_n\) and outputs a classifier \(h_n\), i.e.
\(h_n = \mathcal{T}(D_n) \in \mathcal{H}\). We can now make an informal
hypothesis, after defining the notion of <em>effective model complexity</em>
(from <a href="" target="\_blank">Nakkiran et al.</a> <d-cite key="Nakkiran2019"></d-cite>).</p>

<div class="definition l-body-outset">
  <p><strong>Definition 7</strong> (Effective Model Complexity).
The <em>Effective Model Complexity (EMC)</em> of a training procedure
\(\mathcal{T}\), w.r.t. distribution \(P(X,Y)\), is the maximum number of
samples \(n\) on which \(\mathcal{T}\) achieves on average \(\approx 0\)
training error. That is, for \(\epsilon &gt; 0\):</p>

\[\EMC = \max\{n \in \mathbb{N} | \mathbb{E} L(h_n) \leq \epsilon\}\]

</div>

<div class="theorem l-body-outset">
  <p><strong>Hypothesis</strong> (Generalized Double Descent hypothesis, informal).
For any data distribution \(P(X,Y)\), neural-network-based training
procedure \(\mathcal{T}\), and small \(\epsilon &gt; 0\), if we consider the
task of predicting labels based on \(n\) samples from \(P\) then, as
illustrated on <a href="#fig:double_descent_schema">figure 1</a>:</p>

  <ul>
    <li>
      <p><em>Under-parameterized regime</em>. If \(\EMC\) is sufficiently smaller than
  n, any perturbation of \(\mathcal{T}\) that increases its effective
  complexity will decrease the test error.</p>
    </li>
    <li>
      <p><em>Critically parameterized regime</em>. If \(\EMC \approx n\), then a
  perturbation of \(\mathcal{T}\) that increases its effective
  complexity might decrease or increase the test error.</p>
    </li>
    <li>
      <p><em>Over-parameterized regime</em>. If \(\EMC\) is sufficiently larger than
  n, any perturbation of \(\mathcal{T}\) that increases its effective
  complexity will decrease the test error.</p>
    </li>
  </ul>

</div>

<p>Empirically, this definition of effective model capacity translates into
multiple axis along which the double descent can be observed :
<em>epoch-wise</em>, <em>model-wise</em> (e.g. increasing the width of convolutional
layers or the embedding dimension of transformers) and even with
regularization, by decreasing weight decay.</p>

<p>The double descent along different axis of effective model capacity
is illustrated in the figures below:</p>

<div class="l-page row">
<div class="col-md-6">
<img class="img-fluid rounded z-depth-1" src="/assets/img/posts/double-descent/openai_test.png">
<div class="caption">
      <p><em>Test error as a function of model size and train epochs</em></p>
    </div>
</div>
<div class="col-md-6">
<img class="img-fluid rounded z-depth-1" src="/assets/img/posts/double-descent/openai_train.png">
<div class="caption">
      <p><em>Train error of the corresponding models</em></p>
    </div>
</div>
</div>

<div class="caption">
  <p><strong>Figure 2.</strong> All models are Resnet18s trained on CIFAR-10 with 15% label noise (training labels artificially made incorrect), data-augmentation, and Adam for up to 4K epochs. Taken from from <a href="" target="\_blank">Nakkiran et al.</a> <d-cite key="Nakkiran2019"></d-cite></p>
</div>

<p>In the <a href="/blog/2021/double-descent-2/">next blog post</a> we will talk about the role of inductive biases (including gradient descent) in the double descent phenomenon.</p>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

      <d-bibliography src="/assets/bibliography/2021-05-double-descent.bib"></d-bibliography>
</div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Marc  Lafon. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  
</body>
</html>
